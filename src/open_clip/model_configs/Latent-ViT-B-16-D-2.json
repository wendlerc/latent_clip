{
    "embed_dim": 512,
    "vision_cfg": {
        "image_size": 512, 
        "layers": 12,
        "width": 768,
        "patch_size": 16,
        "latent_encoder_name": "madebyollin/sdxl-vae-fp16-fix",
        "latent_factor": 8,
        "latent_n_channels": 12,
        "latent_n_decoding_layers": 2
    },
    "text_cfg": {
        "context_length": 77,
        "vocab_size": 49408,
        "width": 512,
        "heads": 8,
        "layers": 12
    }
}